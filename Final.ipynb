{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSKrgIYzAP2J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "import random\n",
        "import tarfile\n",
        "import multiprocessing as mp\n",
        "import seaborn as sns\n",
        "import tqdm\n",
        "import requests\n",
        "import sklearn.model_selection as skms\n",
        "import torch\n",
        "import torch.utils.data as td\n",
        "import torch.nn.functional as F\n",
        "import torchvision as tv\n",
        "import torchvision.transforms.functional as TF\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from pandas import DataFrame, Series\n",
        "from PIL import Image\n",
        "import imageio\n",
        "#Import data from drive\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "#from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "# define constants\n",
        "#DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#OUT_DIR = 'results'\n",
        "#RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "data = os.listdir('/content/drive/MyDrive/Project/Cropped/')\n",
        "print (data)\n",
        "print(\"Number of Dog Breeds in Dataset is :\", (len(data)))\n"
      ],
      "metadata": {
        "id": "UeXQkIiivmav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are total 120 folders, each belonging to 1 of the 120 dog breeds**"
      ],
      "metadata": {
        "id": "6B8kauVfwfrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dog labels\n",
        "breeds = [breed.split('-',1)[1] for breed in data] # get labels by splitting the folder name at dash\n",
        "breeds[:15] # view some of the labels"
      ],
      "metadata": {
        "id": "GhiFa9lPwv8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Then, for each of the images, we get the full path to the image (stored in X), as well as its associated label/class/breed (stored in y). This allows us to load the images easily.**"
      ],
      "metadata": {
        "id": "4xm-o2PhxCJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "X = []\n",
        "\n",
        "y = []\n",
        "\n",
        "fullpaths = ['/content/drive/MyDrive/Project/Cropped/{}'.format(dog_class) for dog_class in data]\n",
        "\n",
        "for counter, fullpath in enumerate(fullpaths):\n",
        "    for imgname in os.listdir(fullpath):\n",
        "        X.append([fullpath + '/' + imgname])\n",
        "        y.append(breeds[counter])\n",
        "        \n",
        "X = list(chain.from_iterable(X)) # unnest the lists and join together into one list\n",
        "\n",
        "len(X) # number of pictures"
      ],
      "metadata": {
        "id": "U4Bbibv_et7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random shuffle the images for learning\n",
        "import random\n",
        "# shuffle X and y\n",
        "combined = list(zip(X, y))\n",
        "random.shuffle(combined)\n",
        "X[:], y[:] = zip(*combined)"
      ],
      "metadata": {
        "id": "jS3BcL9IxZ9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a subset to test code\n",
        "X = X[:4500]\n",
        "y = y[:4500]"
      ],
      "metadata": {
        "id": "vAMR8MQ4yC0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoded labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Label and one-hot encoding y labels\n",
        "le = LabelEncoder()\n",
        "le.fit(y)\n",
        "y_ohe = to_categorical(le.transform(y), len(breeds))\n",
        "y_ohe = np.array(y_ohe)"
      ],
      "metadata": {
        "id": "E1LP4xTdyIjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "img_data = np.array([img_to_array(load_img(img, target_size = (224,224)))\n",
        "                     for img in X]) # load, resize images, and store as array\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(img_data, y_ohe,\n",
        "                                                   test_size = 0.2,\n",
        "                                                   stratify=np.array(y), # stratify makes sure that proportion of each class in the output is same as the input\n",
        "                                                   random_state = 2) \n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
        "                                                 test_size = 0.2,\n",
        "                                                 stratify=np.array(y_train),\n",
        "                                                 random_state = 2)\n",
        "print('Training Dataset Size: ', x_train.shape)\n",
        "print('Validation Dataset Size: ', x_val.shape)\n",
        "print('Testing Dataset Size: ', x_test.shape)\n",
        "print('Training Label Size: ', y_train.shape)\n",
        "print('Validation Label Size: ', y_val.shape)\n",
        "print('Testing Label Size: ', y_test.shape)\n",
        "\n",
        "# clear some space from memory\n",
        "import gc\n",
        "del img_data\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "J7XaQbUkyYcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create train generator\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, # only use rescale=1./255 if training from scratch\n",
        "                                  rotation_range = 30,\n",
        "                                  width_shift_range = 0.2,\n",
        "                                  height_shift_range = 0.2,\n",
        "                                  horizontal_flip = True) # CHECK\n",
        "\n",
        "train_generator = train_datagen.flow(x_train, y_train,\n",
        "                                     shuffle = False, batch_size = batch_size, seed = 1)\n",
        "\n",
        "# Create validation generator\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) # do not augment validation data\n",
        "\n",
        "val_generator = val_datagen.flow(x_val, y_val,\n",
        "                                shuffle = False, batch_size = batch_size, seed = 1)"
      ],
      "metadata": {
        "id": "WZ4yOYwfy2AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_id = 16\n",
        "\n",
        "dog_generator = train_datagen.flow(x_train[img_id:img_id+1], y_train[img_id:img_id+1],\n",
        "                                     shuffle = False, batch_size = batch_size, seed = 1)\n",
        "\n",
        "plt.figure(figsize=(30,20))\n",
        "dogs = [next(dog_generator) for i in range(0,5)]\n",
        "for counter, dog in enumerate(dogs): \n",
        "    plt.subplot(1, 5, counter+1)\n",
        "    plt.imshow(dog[0][0])\n",
        "    #plt.axis('off')\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c5LUhh4nzJ8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Model Using Pre-trained Model\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Flatten, Dropout\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# load InceptionV3 pre-trained model\n",
        "base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(base_model) # add pre_trained layers\n",
        "model.add(GlobalAveragePooling2D())\n",
        "#model.add(Flatten()) # flatten to 1-D vector to prepare for fully connected layers\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(len(breeds), activation = 'softmax'))\n",
        "\n",
        "\n",
        "# Freeze pre-trained layers\n",
        "print('Number of trainable weights before freezing the base layer:', len(model.trainable_weights))\n",
        "model.layers[0].trainable = False\n",
        "print('Number of trainable weights after freezing the base layer:', len(model.trainable_weights))\n"
      ],
      "metadata": {
        "id": "ec3zmKmszS3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the Model\n",
        "\n",
        "model.compile(Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "model.summary()"
      ],
      "metadata": {
        "id": "PSDuuAlA0cxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "w6UojKW20oNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "\n",
        "train_steps_per_epoch = x_train.shape[0] // batch_size\n",
        "\n",
        "val_steps_per_epoch = x_val.shape[0] // batch_size\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                             steps_per_epoch = train_steps_per_epoch,\n",
        "                             validation_data = val_generator,\n",
        "                             validation_steps = val_steps_per_epoch,\n",
        "                             epochs = epochs, verbose = 1)"
      ],
      "metadata": {
        "id": "9zaDf97V0tPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Accuracy and Loss \n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Transfer Learning Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(1,epochs+1))\n",
        "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, epochs+1, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, epochs+1, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "metadata": {
        "id": "EyKwotftK7ad"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}