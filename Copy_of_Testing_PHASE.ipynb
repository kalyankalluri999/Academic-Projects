{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_Testing_PHASE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalyankalluri999/Academic-Projects/blob/main/Copy_of_Testing_PHASE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6A0tk6NuS_h",
        "outputId": "e0d67590-23bc-45ca-beea-054b42f1bea1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "metadata": {
        "id": "zL-Iw-ebpBr3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the libraries as shown below\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "6uoEKuY9pHzB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from skimage.transform import resize\n",
        "from IPython.display import SVG\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical, model_to_dot, plot_model"
      ],
      "metadata": {
        "id": "J6xBk4M6u9c5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = ('/content/drive/MyDrive/Newfolder/TEST_data')\n",
        "valid_path =    ('/content/drive/MyDrive/Newfolder/TRAIN_data')\n",
        "IMAGE_SIZE = [224, 224]"
      ],
      "metadata": {
        "id": "2TG3PHqyueuP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "ANjuzz9ypsND"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# don't train existing weights\n",
        "for layer in inception.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "tc8sWXNJpvYc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = glob('/content/drive/MyDrive/Newfolder/TEST_data/*')"
      ],
      "metadata": {
        "id": "T5NAka-0py4F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# our layers - you can add more if you want\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Flatten, Dropout\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(inception) # add pre_trained layers\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "x = Flatten()(inception.output)"
      ],
      "metadata": {
        "id": "PE63nL3Rp-vx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "101c30b6-94c2-45c8-d20e-11b0277d74b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2af1492cdfef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minception\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add pre_trained layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inception' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "# create a model object\n",
        "model = Model(inputs=inception.input, outputs=prediction)"
      ],
      "metadata": {
        "id": "ONPohmNSqCEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the structure of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "M217PeTLqGB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras import optimizers\n",
        "model.compile(Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy']) "
      ],
      "metadata": {
        "id": "hT5YJ_nhqKmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "r7gqXK5RqMmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Newfolder/TEST_data',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "bhu3k_AgqP28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Newfolder/TRAIN_data',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 64,\n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "awMhsW2JqVUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=10,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "metadata": {
        "id": "c81OS_LvqaFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "metadata": {
        "id": "5oCIDo_JE4qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save it as a h5 file\n",
        "from tensorflow.keras.models import load_model\n",
        "model.save('model_inception.h5')"
      ],
      "metadata": {
        "id": "0OtKTVXAu3M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_set)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "Az-evzxqu-OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "0OAKDKaPvDCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "def prepare(filepath):\n",
        "    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
        "    img_array = img_array / 255\n",
        "    new_array = cv2.resize(img_array, (224, 224))\n",
        "    return new_array.reshape(-1, 224, 224, 3)\n",
        "\n",
        "model = tf.keras.models.load_model('model_inception.h5')"
      ],
      "metadata": {
        "id": "oIqDHuMiDR3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict = training_set.class_indices\n",
        "class_dict"
      ],
      "metadata": {
        "id": "YqsColkiEGZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_cls(prediction):\n",
        "    for key, clss in class_dict.items():\n",
        "        if np.argmax(prediction) == clss:\n",
        "            return key"
      ],
      "metadata": {
        "id": "4K3CFaBTElAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict([prepare('/content/drive/MyDrive/Newfolder/TEST_data/Chow/n02112137_1005-0.jpg')])\n",
        "prediction_cls(prediction)"
      ],
      "metadata": {
        "id": "JFx0cCYaEpPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict([prepare('/content/drive/MyDrive/Newfolder/TEST_data/Cairn/n02096177_1000-0.jpg')])\n",
        "prediction_cls(prediction)"
      ],
      "metadata": {
        "id": "F7456RH9CnYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "imageno=np.random.random_integers(low=0, high=test_set.samples)\n",
        "\n",
        "name = test_set.filepaths[imageno]\n",
        "print(name)\n",
        "plt.imshow(mpimg.imread(name))\n",
        "\n",
        "img = Image.open(test_set.filepaths[imageno]).resize((IMAGE_SIZE))\n",
        "probabilities = model.predict(preprocess_input(np.expand_dims(img, axis=0)))\n",
        "breed_list = tuple(zip(test_set.class_indices.values(), test_set.class_indices.keys()))\n",
        "\n",
        "for i in probabilities[0].argsort()[-5:][::-1]: \n",
        "    print(probabilities[0][i], \"  :  \" , breed_list[i])"
      ],
      "metadata": {
        "id": "TCVVE65PTtWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "test_set.reset()\n",
        "predictions = model.predict_generator(test_set, steps=len(test_set))\n",
        "y = np.argmax(predictions, axis=1)\n",
        "print('Classification Report')\n",
        "cr = classification_report(y_true=test_set.classes, y_pred=y, target_names=test_set.class_indices)\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "wSOVOu64UBdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xfGDmw3AUF0M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}